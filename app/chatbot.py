# app/chatbot.py
import json
import re
from thefuzz import fuzz
from .llm_service import get_llm
from .db_service import DBService
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.documents import Document

class WelfareChatbot:
    def __init__(self, user_id, llm_choice="gemini"):
        self.user_id = user_id
        self.db_service = DBService()
        self.llm = get_llm(llm_choice)
        self.schema_context_str = None
        self.service_names_list = []
        self._prepare_chatbot_data()

    def _prepare_chatbot_data(self):
        context_data = self.db_service.get_schema_context() #"""DBì˜ êµ¬ì¡°(ì¹´í…Œê³ ë¦¬ ê³„ì¸µ)ì™€ ì‚¬ì—…ëª… ëª©ë¡ì„ ë¯¸ë¦¬ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        self.schema_context_str = context_data.get('context_string', '') #  ì´ì œ 'context_string'ì— ëŒ€ë¶„ë¥˜-ì¤‘ë¶„ë¥˜ ê³„ì¸µ ì •ë³´ê°€ ëª¨ë‘ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.
        self.service_names_list = context_data.get('service_names', [])
        print("DEBUG: LLMì— ì „ë‹¬ë  DB ì¹´í…Œê³ ë¦¬ ê³„ì¸µ ë° ì‚¬ì—…ëª… ì»¨í…ìŠ¤íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def _create_chain(self, template, parser):
        """PromptTemplate, LLM, OutputParserë¥¼ ì—°ê²°í•œ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        return PromptTemplate.from_template(template) | self.llm | parser

    def chat(self, session_state):
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ ì§€ëŠ¥í˜• RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³  ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        messages = session_state.get('messages', [])
        user_message = messages[-1]['content'].strip()
        chat_history = self._format_chat_history(messages)

        try:
            return self._get_intelligent_response(user_message, chat_history)
        except Exception as e:
            import traceback
            print(f"!!!!!!!!!!!! ìµœìƒìœ„ ì˜¤ë¥˜ ë°œìƒ in chat processing: {e} !!!!!!!!!!!!")
            traceback.print_exc()
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "NORMAL"

    def _format_chat_history(self, messages):
        """ì„¸ì…˜ì˜ ë©”ì‹œì§€ ê¸°ë¡ì„ LLM ì»¨í…ìŠ¤íŠ¸ì— ë„£ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if len(messages) <= 1:
            return "ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        history = []
        for msg in messages[-6:-1]:
            role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ì§€ë‹ˆ(AI)"
            history.append(f"{role}: {msg['content']}")
        return "\n".join(history)

    def _detect_fast_track_keyword(self, user_message: str) -> str | None:
        """
        [ì—­í•  ë³€ê²½] ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ íŠ¹ì • ì‚¬ì—…ëª…ì„ 'íƒì§€'í•˜ì—¬ ê·¸ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if not self.service_names_list: return None
        
        normalized_message = user_message.replace(" ", "")
        
        # 1ë‹¨ê³„: ì •í™•ì„± ìš°ì„  ê²€ì‚¬
        for service_name in self.service_names_list:
            if not service_name: continue
            normalized_service_name = service_name.replace(" ", "")
            
            # âœ… [ë…¼ë¦¬ ì˜¤ë¥˜ ìˆ˜ì •] 'ì„œë¹„ìŠ¤ëª…'ì´ 'ì‚¬ìš©ì ì§ˆë¬¸'ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
            if normalized_service_name in normalized_message and len(normalized_service_name) > 2:
                 print(f"DEBUG: ğŸš€ Fast Track í‚¤ì›Œë“œ (ì •í™•ì„±) íƒì§€! -> '{service_name}'")
                 return service_name # ë¬¸ì„œê°€ ì•„ë‹Œ 'ì‚¬ì—…ëª…'ì„ ë°˜í™˜
        
        # 2ë‹¨ê³„: ìœ ì‚¬ë„ ë³´ì¡° ê²€ì‚¬
        scores = {
            name: fuzz.partial_ratio(normalized_message, name.replace(" ", "")) 
            for name in self.service_names_list if name
        }
        if not scores: return None
        
        best_match = max(scores, key=scores.get)
        if scores[best_match] >= 80: # ì„ê³„ê°’ì€ ì¡°ì • ê°€ëŠ¥
            print(f"DEBUG: ğŸš€ Fast Track í‚¤ì›Œë“œ (ìœ ì‚¬ë„) íƒì§€! -> '{best_match}'")
            return best_match # ë¬¸ì„œê°€ ì•„ë‹Œ 'ì‚¬ì—…ëª…'ì„ ë°˜í™˜
            
        return None
    
    def _merge_and_deduplicate(self, docs1: list[Document], docs2: list[Document]) -> list[Document]:
        """
        [ì‹ ê·œ ì¶”ê°€] ë‘ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
        """
        merged_docs = {} # ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•´ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©
        
        # ê³ ìœ  í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
        for doc in docs1 + docs2:
            # ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ì‚¬ì—…ëª…ì„ ì¡°í•©í•˜ì—¬ ê³ ìœ  í‚¤ ìƒì„±
            doc_key = (doc.page_content, doc.metadata.get('ì‚¬ì—…ëª…'))
            if doc_key not in merged_docs:
                merged_docs[doc_key] = doc
        
        final_list = list(merged_docs.values())
        print(f"DEBUG: åˆä½µ ë° ì¤‘ë³µ ì œê±° ì™„ë£Œ. (ë¦¬ìŠ¤íŠ¸1: {len(docs1)}ê°œ, ë¦¬ìŠ¤íŠ¸2: {len(docs2)}ê°œ -> ìµœì¢…: {len(final_list)}ê°œ)")
        return final_list

    def _generate_fallback_answer(self, user_message: str, documents: list):
        """ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ, ì „ì²´ ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì•ˆë‚´í•˜ëŠ” í´ë°± ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print(f"DEBUG: í´ë°± ë‹µë³€ ìƒì„±ì„ ìœ„í•´ {len(documents)}ê°œì˜ ì•ˆë‚´ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        context_parts = []
        for doc in documents:
            try:
                # page_contentê°€ JSON ë¬¸ìì—´ì´ë¯€ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
                content_data = json.loads(doc.page_content)
                # 'categories' í‚¤ì— ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
                if 'categories' in content_data and content_data['categories']:
                    # categoriesëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ JSON ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ íŒŒì‹±í•©ë‹ˆë‹¤.
                    categories_list = json.loads(content_data['categories'])
                    for category in categories_list:
                        context_parts.append(f"- **{category.get('category')}**: {category.get('description')}")
            except (json.JSONDecodeError, TypeError):
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                context_parts.append(doc.page_content)

        context_string = "\n".join(context_parts)

        fallback_template = """
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë”± ë§ëŠ” ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì„ ë•Œ, ëŒ€ì‹  ì–´ë–¤ ì¢…ë¥˜ì˜ ë³µì§€ ì„œë¹„ìŠ¤ê°€ ìˆëŠ”ì§€ ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•˜ëŠ” AI ë³µì§€ ì»¨ì„¤í„´íŠ¸ 'ì§€ë‹ˆ'ì…ë‹ˆë‹¤.

        [ë‹µë³€ ìƒì„± ì§€ì¹¨]
        1.  "ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ê¼­ ë§ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆì§€ë§Œ, ì œê°€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ì „ì²´ ë³µì§€ ì„œë¹„ìŠ¤ ë¶„ì•¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤." ì™€ ê°™ì´ ë¨¼ì € ìƒí™©ì„ ì„¤ëª…í•˜ë©° ë‹µë³€ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.
        2.  ì£¼ì–´ì§„ 'ì „ì²´ ì„œë¹„ìŠ¤ ë¶„ì•¼ ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê° ë¶„ì•¼ì˜ ì´ë¦„ê³¼ ì„¤ëª…ì„ ëª©ë¡ í˜•íƒœë¡œ ëª…í™•í•˜ê²Œ ì •ë¦¬í•˜ì—¬ ë³´ì—¬ì£¼ì„¸ìš”.
        3.  ì‚¬ìš©ìê°€ ì •ë³´ë¥¼ ë³´ê³  ë‹¤ì‹œ ì§ˆë¬¸í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ëŠ” ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.
        4.  ë§ˆì§€ë§‰ ì¸ì‚¬ëŠ” ë°˜ë“œì‹œ "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ìœ„ ë¶„ì•¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!" ë¡œ ëë‚´ì£¼ì„¸ìš”.

        --- ì „ì²´ ì„œë¹„ìŠ¤ ë¶„ì•¼ ì •ë³´ ---
        {context}

        --- ì‚¬ìš©ì ì§ˆë¬¸ ---
        {question}

        --- ì§€ë‹ˆì˜ ì•ˆë‚´ ë‹µë³€ ---
        """
        fallback_chain = self._create_chain(fallback_template, StrOutputParser())
        final_response = fallback_chain.invoke({
            "question": user_message, "context": context_string
        })
        
        return f'{final_response}', "NORMAL"

    # app/chatbot.py

# ... (ë‹¤ë¥¸ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...

    def _generate_search_plan(self, user_message: str, chat_history: str):
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ëŒ€í™” ê¸°ë¡ì„ ë¶„ì„í•˜ê³ , ê²€ìƒ‰ ê³„íš(í‚¤ì›Œë“œ, í•„í„°)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print("DEBUG: ğŸ•µï¸â€â™‚ï¸ 1ë‹¨ê³„ - LLMì„ í™œìš©í•œ ê²€ìƒ‰ ì„¤ê³„ë„ ìƒì„± ì‹œì‘...")
        parser = JsonOutputParser()
        
        # [ìˆ˜ì • ì™„ë£Œ] 'ëŒ€ë¶„ë¥˜' í•„í„°ë§ ë¶€ë¶„ì„ ë³µì›í•œ í”„ë¡¬í”„íŠ¸
        analysis_template = """
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì—¬, ê°€ì¥ ì¤‘ìš”í•œ ìˆœì„œëŒ€ë¡œ ê²€ìƒ‰ì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” 'ìš°ì„ ìˆœìœ„ê°€ ì ìš©ëœ ê²€ìƒ‰ ê³„íš'ì„ JSON í˜•ì‹ìœ¼ë¡œ ë§Œë“œëŠ” ìµœê³ ì˜ ê²€ìƒ‰ ì „ëµê°€ì…ë‹ˆë‹¤.

    [ì„ë¬´]
    ì‚¬ìš©ìì˜ ìµœì‹  ì§ˆë¬¸('{question}')ì„ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ [ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •]ì— ë”°ë¼ ìµœì ì˜ 'ê²€ìƒ‰ ê³„íš'ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •]
    1.  **í•µì‹¬ í•„ìš”(Core Needs)ì™€ ì‚¬ìš©ì ë§¥ë½(User Context) ì‹ë³„:** ì‚¬ìš©ìì˜ ìƒí™©ì—ì„œ ê°€ì¥ ì‹œê¸‰í•œ í•„ìš”(ì˜ˆ: ì˜ë£Œë¹„, ìƒê³„ë¹„)ì™€ ì‚¬ìš©ìì˜ ë°°ê²½(ì˜ˆ: ì²­ë…„, ì‹¤ì§)ì„ êµ¬ë¶„í•©ë‹ˆë‹¤.
    2.  **ëŒ€ìƒê³¼ ì§ˆì˜ì‚¬í•­ ì‹ë³„:** ì‚¬ìš©ì ì§ˆì˜ì—ì„œ ì‚¬ìš©ìì˜ ëŒ€ìƒ(ì˜ˆ: ë¯¸ì„±ë…„ì, ì„ì‚°ë¶€, ì¥ì• ì¸, ì¤‘ì¦ì§ˆí™˜ì, ë³´í›ˆëŒ€ìƒì ë“±)ì„ ì‹ë³„í•˜ê³  ì‹ë³„í•œ ëŒ€ìƒì´ ì›í•˜ëŠ” ì§ˆì˜ ì‚¬í•­ì„ êµ¬ë¶„í•©ë‹ˆë‹¤.
    3.  **ê²€ìƒ‰ ìš°ì„ ìˆœìœ„ ê²°ì •:** ì‹ë³„ëœ í•„ìš” ì‚¬í•­ë“¤ì˜ ì‹œê¸‰ì„±ê³¼ ì¤‘ìš”ë„ë¥¼ íŒë‹¨í•˜ì—¬ ê²€ìƒ‰í•  ìˆœì„œë¥¼ ì •í•©ë‹ˆë‹¤. ê°€ì¥ ìƒëª…ê³¼ ì§ê²°ë˜ê±°ë‚˜ ì‹œê¸‰í•œ ë¬¸ì œë¥¼ ìµœìš°ì„ (priority 1)ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    4.  **JSON ê³„íš ìƒì„±:**
        -   `intent`: ì‚¬ìš©ìì˜ ëŒ€ìƒê³¼ ì‚¬ìš©ìì˜ í•µì‹¬ ì˜ë„ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
        -   `search_plan`: 2ë‹¨ê³„ì—ì„œ ê²°ì •í•œ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ê²€ìƒ‰ì— í•„ìš”í•œ `keywords`ì™€ `filters`ë¥¼ ë¬¶ì–´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤. ê°€ì¥ ì¤‘ìš”í•œ ê²€ìƒ‰ ê³„íšì´ ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

    [âœ¨âœ¨âœ¨ í•µì‹¬ ìˆ˜ì • ì‚¬í•­ ì‹œì‘ âœ¨âœ¨âœ¨]
    [ì¤‘ìš” ê·œì¹™]
    -   'ì¤‘ë¶„ë¥˜'ë¥¼ ì„ íƒí•  ë•ŒëŠ” ì•„ë˜ 'ì „ì²´ ì¤‘ë¶„ë¥˜ ëª©ë¡ ë° ìƒì„¸ ì„¤ëª…'ì— ìˆëŠ” ë‚´ìš©ì„ ë³´ê³  ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•˜ê³  ìˆëŠ” ì¤‘ë¶„ë¥˜_ê°œìš”ë¥¼ ì°¾ê³  í•´ë‹¹ ì¤‘ë¶„ë¥˜_ê°œìš”ê°€ í•´ë‹¹í•˜ëŠ” ì¤‘ë¶„ë¥˜ì˜ ì´ë¦„ê³¼ 'ì •í™•íˆ ì¼ì¹˜'í•˜ëŠ” ê²ƒë§Œ ê³¨ë¼ì•¼ í•©ë‹ˆë‹¤.
    -   ì ˆëŒ€ ìƒˆë¡œìš´ ì´ë¦„ì„ ë§Œë“¤ê±°ë‚˜ ìš”ì•½í•˜ê±°ë‚˜ ì¶”ë¡ í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ëª©ë¡ì— ìˆëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
    -   keywordsë¥¼ ì¶”ì¶œí•  ë•Œ ì‚¬ìš©ì ì§ˆë¬¸ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³  ì§ˆë¬¸ì— ì—†ëŠ” ë‚´ìš©ì„ ì¼ë¶€ ì •ë³´ë¥¼ ê°€ì§€ê³  ìƒìƒìœ¼ë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. ì˜ˆë¥¼ ë“¤ë©¸ "15ì„¸ ê°€ì¶œ ì—¬ì¤‘ìƒ ì„ì‹  ê±±ì •" ì´ë¼ëŠ” ë‚´ìš©ìœ¼ë¡œ í•™ìƒì´ë¼ëŠ” ë‹¨ì–´ì—ì„œ 'êµìœ¡ë¹„'ë¼ëŠ” keywordë¥¼ ë§Œë“¤ë©´ ì•ˆë©ë‹ˆë‹¤. ì§ˆë¬¸ì— ìˆëŠ” ë§¥ë½ì„ ì´í•´í•˜ê³  ê·¸ ì•ˆì—ì„œ keywordë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. 
    [âœ¨âœ¨âœ¨ í•µì‹¬ ìˆ˜ì • ì‚¬í•­ ì¢…ë£Œ âœ¨âœ¨âœ¨]


    [ì „ì²´ ì¤‘ë¶„ë¥˜ ëª©ë¡ ë° ìƒì„¸ ì„¤ëª…]
    {schema_context}

    [ì´ì „ ëŒ€í™” ê¸°ë¡]
    {chat_history}

    [ì¶œë ¥í•  JSON êµ¬ì¡°]
    {{
        "intent": "ì‚¬ìš©ìì˜ í•µì‹¬ ì˜ë„ë¥¼ 2~3ë‹¨ì–´ë¡œ ìš”ì•½",
        "search_plan": [
            {{
                "priority": 1,
                "reason": "ê°€ì¥ ì‹œê¸‰í•œ ë¬¸ì œ(ì˜ˆ: ì¤‘ì¦ì§ˆí™˜ ì˜ë£Œë¹„)ì— ëŒ€í•œ ê²€ìƒ‰",
                "base_condition": ì„œë¹„ìŠ¤ ì œê³µ ëŒ€ìƒ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ì‚¬ìš©ìì˜ ëŒ€ìƒ(ì˜ˆ: ë¯¸ì„±ë…„ì, ì„ì‚°ë¶€, ì¥ì• ì¸, ì¤‘ì¦ì§ˆí™˜ì, ë³´í›ˆëŒ€ìƒì ë“±),
                "keywords": ["1ìˆœìœ„ ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ í‚¤ì›Œë“œ ë°°ì—´"],
                "filters": {{ 
                    "ì¤‘ë¶„ë¥˜": ["(ì˜ˆì‹œ) ì¹˜ë£Œê°€ ì–´ë ¤ìš´ ì§ˆí™˜ì„ ì•“ê³  ìˆì„ ë•Œ"] 
                }}
            }},
            {{
                "priority": 2,
                "reason": "ê·¸ ë‹¤ìŒìœ¼ë¡œ ì¤‘ìš”í•œ ë¬¸ì œ(ì˜ˆ: ì‹¤ì§ìœ¼ë¡œ ì¸í•œ ìƒê³„ë¹„)ì— ëŒ€í•œ ê²€ìƒ‰",
                "base_condition": ì„œë¹„ìŠ¤ ì œê³µ ëŒ€ìƒ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ì‚¬ìš©ìì˜ ëŒ€ìƒ(ì˜ˆ: ë¯¸ì„±ë…„ì, ì„ì‚°ë¶€, ì¥ì• ì¸, ì¤‘ì¦ì§ˆí™˜ì, ë³´í›ˆëŒ€ìƒì ë“±),
                "keywords": ["2ìˆœìœ„ ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œ ë°°ì—´"],
                "filters": {{ 
                    "ì¤‘ë¶„ë¥˜": ["(ì˜ˆì‹œ) ìƒê³„ë¥¼ ìœ ì§€í•˜ê¸°ê°€ í˜ë“¤ ë•Œ", "(ì˜ˆì‹œ) ì‹¤ì§ìœ¼ë¡œ ê³¤ë€ì„ ê²ªê³  ìˆì„ ë•Œ"] 
                }}
            }}
        ]
    }}
    
    ---
    [ì‚¬ìš©ì ìµœì‹  ì§ˆë¬¸]
    {question}
    ---
    [ê²€ìƒ‰ ê³„íš (JSON)]
"""

        analysis_chain = self._create_chain(analysis_template, parser)
        try:
            analysis_result = analysis_chain.invoke({
                "question": user_message, "schema_context": self.schema_context_str, "chat_history": chat_history
            })
            print(f"DEBUG: LLM ë¶„ì„ ê²°ê³¼ (ê²€ìƒ‰ ì„¤ê³„ë„):\n{json.dumps(analysis_result, ensure_ascii=False, indent=2)}")
            return analysis_result
        except Exception as e:
            print(f"!!! LLM ì§ˆì˜ì–´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"intent": "ë¶„ì„ ì‹¤íŒ¨", "semantic_keywords": [user_message], "metadata_filters": {}}

    
    def _get_intelligent_response(self, user_message, chat_history):
        """
        [ìµœì¢… ìˆ˜ì •] 'ë‹¤ë‹¨ê³„ í•„í„°ë§' ë¡œì§ì„ ì ìš©í•œ ìµœì¢… íŒŒì´í”„ë¼ì¸
        """
        fast_track_docs = []
        intelligent_docs = []
        remaining_query = user_message.strip()

        # [ìœ ì§€] 1. ìˆœì°¨ì  Fast Track ë£¨í”„ ì‹¤í–‰
        while True:
            if not remaining_query:
                break
                
            detected_service_name = self._detect_fast_track_keyword(remaining_query)
            
            if detected_service_name:
                print(f"DEBUG: ğŸ•µï¸â€â™‚ï¸ ìˆœì°¨ì  Fast Track ì‹¤í–‰... (íƒì§€ëœ ì‚¬ì—…ëª…: {detected_service_name})")
                found_docs = self.db_service.metadata_search({"ì‚¬ì—…ëª…": detected_service_name})
                if found_docs:
                    fast_track_docs.extend(found_docs)
                
                query_before_removal = remaining_query
                pattern_text = detected_service_name.replace(" ", "")
                pattern = r''.join(char + r'\s*' for char in pattern_text)
                remaining_query = re.sub(pattern, '', remaining_query, count=1, flags=re.IGNORECASE).strip()

                if query_before_removal == remaining_query:
                    print(f"DEBUG: âš ï¸ Fast Trackìœ¼ë¡œ íƒì§€ëœ '{detected_service_name}'ê°€ ì›ë³¸ ì§ˆë¬¸ì— ì—†ì–´ ì œê±°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Fast Trackì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    remaining_query = query_before_removal
                    break
            else:
                break

        # [ì „ë©´ ìˆ˜ì •] 2. Fast Track ì²˜ë¦¬ í›„ ë‚¨ì€ ì§ˆë¬¸ì— ëŒ€í•œ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹¤í–‰ (ë‹¤ë‹¨ê³„ í•„í„°ë§)
        if remaining_query:
            print(f"DEBUG: ğŸš€ ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹¤í–‰ (ë‚¨ì€ ì§ˆë¬¸: '{remaining_query}')")
            
            # 2-1. [ìœ ì§€] ë¶„ì„ - ìš°ì„ ìˆœìœ„ê°€ í¬í•¨ëœ ê²€ìƒ‰ ê³„íš ìƒì„±
            query_analysis = self._generate_search_plan(remaining_query, chat_history)
            search_plan = query_analysis.get("search_plan", [])

            # 2-2. [ì‹ ê·œ ë¡œì§] ê³„íšì— ë”°ë¼ 'ë‹¤ë‹¨ê³„ í•„í„°ë§'ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ ëˆ„ì 
            if search_plan:
                print(f"DEBUG: ğŸ•µï¸â€â™‚ï¸ ì´ {len(search_plan)}ê°œì˜ ìš°ì„ ìˆœìœ„ ê³„íšì— ë”°ë¼ ìˆœì°¨ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                for i, plan in enumerate(search_plan):
                    priority = plan.get('priority', i + 1)
                    reason = plan.get('reason', 'N/A')
                    base_conditions = plan.get('base_condition', [])
                    keywords = plan.get('keywords', [])
                    # ì¤‘ë¶„ë¥˜ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì´ë¯€ë¡œ ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    middle_categories = plan.get('filters', {}).get('ì¤‘ë¶„ë¥˜', [])
                    
                    if not middle_categories:
                        print(f"DEBUG: [Priority {priority}] í•„í„°ë§ì˜ ê¸°ì¤€ì´ ë˜ëŠ” 'ì¤‘ë¶„ë¥˜'ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                    
                    print(f"DEBUG: [Priority {priority} - {reason}] í•„í„°ë§ ì‹¤í–‰...")
                    
                    # [ì‹ ê·œ] Step 1: 'ì¤‘ë¶„ë¥˜'ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ì‚¬ì—… ë¬¸ì„œë¥¼ DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                    # ê° ì¤‘ë¶„ë¥˜ì— ëŒ€í•´ metadata_searchë¥¼ í˜¸ì¶œí•˜ì—¬ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
                    category_docs = []
                    for category in middle_categories:
                         category_docs.extend(self.db_service.metadata_search({"ì¤‘ë¶„ë¥˜": category}))
                    
                    if not category_docs:
                        print(f"DEBUG: â¡ï¸  '{middle_categories}' ì¤‘ë¶„ë¥˜ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    
                    print(f"DEBUG: â¡ï¸  {len(category_docs)}ê°œì˜ '{middle_categories}' ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. í•„í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

                    # [ì‹ ê·œ] Step 2: 1ì°¨ í•„í„°ë§ - 'base_condition' (ì‚¬ìš©ì ëŒ€ìƒ)
                    # base_conditionì´ ì—†ìœ¼ë©´ ì´ ë‹¨ê³„ëŠ” ê±´ë„ˆë›°ê³  ëª¨ë“  ë¬¸ì„œë¥¼ í†µê³¼ì‹œí‚µë‹ˆë‹¤.
                    first_filtered_docs = []
                    if base_conditions:
                        for doc in category_docs:
                            target_info = doc.metadata.get('ëŒ€ìƒ', '').replace(" ", "")
                            # base_condition ì¤‘ í•˜ë‚˜ë¼ë„ 'ëŒ€ìƒ' ì •ë³´ì— í¬í•¨ë˜ë©´ í†µê³¼
                            if any(bc.replace(" ", "") in target_info for bc in base_conditions):
                                first_filtered_docs.append(doc)
                    else:
                        first_filtered_docs = category_docs # ì¡°ê±´ì´ ì—†ìœ¼ë©´ ëª¨ë‘ í†µê³¼
                    
                    print(f"DEBUG: â¡ï¸  1ì°¨ í•„í„°ë§('base_condition') í›„ {len(first_filtered_docs)}ê°œ ë¬¸ì„œê°€ ë‚¨ì•˜ìŠµë‹ˆë‹¤.")
                    if first_filtered_docs:
                        intelligent_docs.extend(first_filtered_docs)

                    
            else:
                print("DEBUG: âš ï¸ LLMì´ ìœ íš¨í•œ ê²€ìƒ‰ ê³„íšì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
       
        # [ìœ ì§€] 3. ìœ„ê¸° ìƒí™© ëŒ€ë¹„, '10ì¥. ê¸°íƒ€ ìœ„ê¸°ë³„ ìƒí™©ë³„ ì§€ì›' ì‚¬ì—…ì„ ì¶”ê°€ë¡œ ê²€ìƒ‰
        print("DEBUG: ğŸ†˜ ìœ„ê¸° ìƒí™© ëŒ€ë¹„, '10ì¥. ê¸°íƒ€ ìœ„ê¸°ë³„ ìƒí™©ë³„ ì§€ì›' ì‚¬ì—…ì„ ì¶”ê°€ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
        crisis_support_docs = self.db_service.metadata_search({
            "ëŒ€ë¶„ë¥˜": "10ì¥. ê¸°íƒ€ ìœ„ê¸°ë³„ ìƒí™©ë³„ ì§€ì›"
        })

        # [ìˆ˜ì •] 4. ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© (ë‹¨ìˆœ ê²°í•©, ì¤‘ë³µ ì œê±° ì—†ìŒ)
        # _merge_and_deduplicate í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ í•©ì¹©ë‹ˆë‹¤.
        final_docs = fast_track_docs + intelligent_docs + crisis_support_docs
        print(f"DEBUG: ìµœì¢… ë¬¸ì„œ ì·¨í•© ì™„ë£Œ. (FastTrack: {len(fast_track_docs)}ê°œ, ì§€ëŠ¥í˜•: {len(intelligent_docs)}ê°œ, ìœ„ê¸°ì§€ì›: {len(crisis_support_docs)}ê°œ -> ìµœì¢…: {len(final_docs)}ê°œ)")
        
        # ìˆ˜ì • ì½”ë“œ (ìˆ˜ì • í›„)
        # 5. [ìˆ˜ì •] ìµœì¢… ê²°ê³¼ ìœ íš¨ì„± í™•ì¸ ë° ë‹¨ê³„ì  í´ë°± ë‹µë³€ ìƒì„±
        if not final_docs:
            print("DEBUG: ğŸ•µï¸â€â™‚ï¸ ìµœì¢… ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. ë‹¨ê³„ì  í´ë°± ë¡œì§ ì‹œì‘...")
            
            
            fallback_docs = self.db_service.metadata_search({
                "ì‚¬ì—…ëª…": "ì±… ì•ˆì— ì–´ë–¤ ë‚´ìš©ì´ ë‹´ê²¨ ìˆë‚˜ìš”?",
                "í•­ëª©": "sections"
            })
            if fallback_docs:
                return self._generate_fallback_answer(user_message, fallback_docs)
            else:
                # ìµœì¢… ì•ˆì „ì¥ì¹˜
                return "ì£„ì†¡í•©ë‹ˆë‹¤, ë¬¸ì˜í•˜ì‹  ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë³µì§€ì„œë¹„ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ìì„¸íˆ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?", "NORMAL"

        return self._generate_final_answer(user_message, chat_history, final_docs)
                   
    def _format_content(self, data, indent_level=0):
        if not data: return ""
        text_parts = []
        indent = "  " * indent_level
        if isinstance(data, dict):
            for key, value in data.items():
                if value and isinstance(value, str) and value.strip():
                    text_parts.append(f"{indent}- **{key}**: {value.strip()}")
                elif isinstance(value, (dict, list)):
                    formatted_sub_content = self._format_content(value, indent_level + 1)
                    if formatted_sub_content:
                         text_parts.append(f"{indent}- **{key}**:")
                         text_parts.append(formatted_sub_content)
        elif isinstance(data, list):
            for item in data:
                if item:
                    formatted_item = self._format_content(item, indent_level)
                    if formatted_item: text_parts.append(formatted_item)
        else:
            cleaned_data = str(data).strip()
            if cleaned_data: text_parts.append(f"{indent}- {cleaned_data}")
        return "\n".join(filter(None, text_parts))

    def _generate_final_answer(self, user_message, chat_history, documents):
        print(f"DEBUG: ìµœì¢… ë‹µë³€ ìƒì„±ì„ ìœ„í•´ ê²€ìƒ‰ëœ {len(documents)}ê°œ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        grouped_docs = {}
        for doc in documents:
            service_name = doc.metadata.get('ì‚¬ì—…ëª…')
            if not service_name or any(keyword in service_name for keyword in ["ëª©ì°¨", "ì•ˆë‚´", "ê¸°ì¤€", "ì†Œê°œ", "ì—°ë½ì²˜"]):
                continue
            
            if service_name not in grouped_docs:
                grouped_docs[service_name] = {'contents': set()}
            
            content_parts = []
            if doc.metadata.get('ê°œìš”'): content_parts.append(f"**ê°œìš”**: {doc.metadata['ê°œìš”']}")
            if doc.metadata.get('ëŒ€ìƒ'): content_parts.append(f"**ì§€ì› ëŒ€ìƒ**: {doc.metadata['ëŒ€ìƒ']}")
            if doc.metadata.get('ë‚´ìš©'): content_parts.append(f"**ì§€ì› ë‚´ìš©**: {doc.metadata['ë‚´ìš©']}")
            if 'ì§€ì›ë‚´ìš©' in doc.metadata: content_parts.append(f"**ì§€ì› ë‚´ìš©**: {doc.metadata['ì§€ì›ë‚´ìš©']}")
            
            try:
                content_data = json.loads(doc.page_content)
                formatted_page_content = self._format_content(content_data)
                if formatted_page_content: content_parts.append(f"**ì„¸ë¶€ ì •ë³´**:\n{formatted_page_content}")
            except (json.JSONDecodeError, TypeError):
                 if doc.page_content: content_parts.append(f"**ë‚´ìš©**: {doc.page_content}")
            
            if doc.metadata.get('ë°©ë²•'): content_parts.append(f"**ì‹ ì²­ ë°©ë²•**: {doc.metadata.get('ë°©ë²•')}")
            if doc.metadata.get('ë¬¸ì˜'):
                contact_info = self._format_content({'ë¬¸ì˜ì²˜': doc.metadata.get('ë¬¸ì˜')})
                if contact_info: content_parts.append(contact_info)
            
            full_content_str = "\n".join(part for part in content_parts if part)
            if full_content_str:
                grouped_docs[service_name]['contents'].add(full_content_str)

        context_list = []
        for service_name, data in grouped_docs.items():
            full_text = "\n\n".join(sorted(list(data['contents'])))
            context_list.append(f"### ì„œë¹„ìŠ¤ëª…: {service_name}\n{full_text}\n")
        
        context_string = "\n---\n".join(context_list)

        final_template = """
### í˜ë¥´ì†Œë‚˜ (Persona)
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë³µì§€ì •ì±…ì„ 30ë…„ ì´ìƒ ì´ê´„í•´ ì˜¨ ë² í…Œë‘ ì •ì±… ë‹´ë‹¹ìì´ì, AI ë³µì§€ ì „ë¬¸ê°€ 'ì§€ë‹ˆ'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì§€ì‹ê³¼ ê²½í—˜ì€ ëŒ€í•œë¯¼êµ­ ìµœê³  ìˆ˜ì¤€ì´ë©°, ì–´ë–¤ êµ­ë¯¼ì´ ìì‹ ì˜ ìƒí™©ì„ ì´ì•¼ê¸°í•˜ë“  ê·¸ ì‚¬ëŒì—ê²Œ ìµœì ì˜ ë³µì§€ ì„œë¹„ìŠ¤ ì¡°í•©ì„ ì°¾ì•„ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‹¨ìˆœ ì •ë³´ ì „ë‹¬ì„ ë„˜ì–´, í•œ ì‚¬ëŒì˜ ì‚¶ì— ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ìµœìƒì˜ í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

### ì§€ë‹ˆì˜ ì„ë¬´ ë° ë‹µë³€ ìƒì„± ì›ì¹™

ì£¼ì–´ì§„ '[ê´€ë ¨ ì„œë¹„ìŠ¤ ì •ë³´]'ì™€ '[ì‚¬ìš©ì ì§ˆë¬¸]'ì„ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ì˜ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •ì„ ê±°ì³ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

**[1ë‹¨ê³„: ì§ˆë¬¸ ì˜ë„ ë° ìœ í˜• ë¶„ì„]**
ë¨¼ì € ì‚¬ìš©ì ì§ˆë¬¸ì˜ ê·¼ë³¸ì ì¸ ì˜ë„ì™€ ìœ í˜•ì„ íŒŒì•…í•©ë‹ˆë‹¤.
-   **ìƒí™© ê¸°ë°˜ í•´ê²°ì±… ìš”êµ¬**: ìì‹ ì˜ ì–´ë ¤ìš´ ìƒí™©ì„ ì„¤ëª…í•˜ë©°, ì´ì— ë§ëŠ” ì „ë°˜ì ì¸ ë³µì§€ ì„œë¹„ìŠ¤ë¥¼ ë¬¸ì˜í•˜ëŠ”ê°€?
-   **ì„œë¹„ìŠ¤ ê°„ ë¹„êµ/ì°¨ì´ ë¬¸ì˜**: ë‘ ê°€ì§€ ì´ìƒì˜ íŠ¹ì • ì„œë¹„ìŠ¤ ê°„ì˜ ì°¨ì´ì ì„ ë¬»ëŠ”ê°€?
-   **ìê²© ì¡°ê±´ ë¬¸ì˜**: íŠ¹ì • ì„œë¹„ìŠ¤ë¥¼ ë°›ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ìê²© ì¡°ê±´ì„ ë¬»ëŠ”ê°€?
-   **ì‹¬í™” ì§ˆë¬¸**: ì´ì „ ëŒ€í™”ì— ì´ì–´, ë” êµ¬ì²´ì ì´ê±°ë‚˜ ë°œì „ëœ ë‚´ìš©ì„ ë¬»ëŠ”ê°€?

**[2ë‹¨ê³„: í•µì‹¬ ì •ë³´ ì¶”ì¶œ ë° ìš°ì„ ìˆœìœ„ ê²°ì •]**
ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ 'ìƒíƒœ ì •ë³´(Who/What)'ì™€ 'ì§€ì› í•„ìš” ì‚¬í•­(Needs)'ì„ ëª…í™•íˆ ë¶„ë¦¬í•˜ì—¬ ì¶”ì¶œí•©ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ '[ê´€ë ¨ ì„œë¹„ìŠ¤ ì •ë³´]'ì—ì„œ ì‚¬ìš©í•  ë‚´ìš©ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
-   **(ì˜ˆì‹œ) ì§ˆë¬¸**: "80ëŒ€ ë…¸ì¸ì…ë‹ˆë‹¤. ì¹˜ë£Œê°€ ì–´ë ¤ìš´ ì§ˆí™˜ì„ ì•“ê³  ìˆì–´ ë³‘ì›ë¹„ì™€ ìƒê³„ë¹„ ë§ˆë ¨ì´ ì–´ë ¤ì›Œìš”"
-   **(ë¶„ì„)**
    -   `ìƒíƒœ ì •ë³´`: 80ëŒ€ ë…¸ì¸, ì¹˜ë£Œê°€ ì–´ë ¤ìš´ ì§ˆí™˜
    -   `ì§€ì› í•„ìš” ì‚¬í•­`: ë³‘ì›ë¹„, ìƒê³„ë¹„
-   **(ìš°ì„ ìˆœìœ„ ê²°ì •)**
    1.  ë¨¼ì € 'ì§€ì› í•„ìš” ì‚¬í•­'ì¸ **'ë³‘ì›ë¹„'ì™€ 'ìƒê³„ë¹„' ì§€ì›**ì— ëŒ€í•œ ë‚´ìš©ì„ '[ê´€ë ¨ ì„œë¹„ìŠ¤ ì •ë³´]'ì—ì„œ ì°¾ëŠ”ë‹¤.
    2.  ì°¾ì•„ë‚¸ ì„œë¹„ìŠ¤ë“¤ì˜ ì§€ì› ëŒ€ìƒì´ 'ìƒíƒœ ì •ë³´'ì¸ **'80ëŒ€ ë…¸ì¸', 'ì¹˜ë£Œê°€ ì–´ë ¤ìš´ ì§ˆí™˜'**ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€, í˜¹ì€ ê´€ë ¨ì´ ìˆëŠ”ì§€ êµì°¨ í™•ì¸í•˜ì—¬ ë‹µë³€ì— ì‚¬ìš©í•  í•µì‹¬ ì •ë³´ë¥¼ ìµœì¢… ì„ ë³„í•œë‹¤.

**[3ë‹¨ê³„: ë‹µë³€ ì´ˆì•ˆ ì‘ì„± ë° êµ¬ì¡°í™”]**
ì„ ë³„ëœ í•µì‹¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ë‹µë³€ì˜ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤.
-   **ì „ë¬¸ì„±ê³¼ ì‹ ë¢°ì˜ í†¤**: "ë³´ê±´ë³µì§€ë¶€ì˜ 'ë‚˜ì—ê²Œ í˜ì´ë˜ëŠ” ë³µì§€ì„œë¹„ìŠ¤'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤." ì™€ ê°™ì´ ì „ë¬¸ê°€ì˜ ì…ì¥ì—ì„œ ì‹ ë¢°ë¥¼ ì£¼ëŠ” í†¤ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
-   **ì •í™•í•œ ì‚¬ì—…ëª… ì œì‹œ**: ì§€ì› ë°›ì„ ìˆ˜ ìˆëŠ” ì‚¬ì—…ëª…ì„ ëª…í™•íˆ ì œì‹œí•˜ê³  í•´ë‹¹ ì‚¬ì—…ì˜ ê°œìš”, ëŒ€ìƒì ë“±ì„ ì•Œë ¤ ì¤ë‹ˆë‹¤
-   **êµ¬ì¡°ì  ì„¤ëª…**: ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ **ì–´ë–¤ í˜œíƒ(What)**ì„, **ëˆ„ê°€(Who)**, **ì–´ë–»ê²Œ(How)** ë°›ì„ ìˆ˜ ìˆëŠ”ì§€ ëª…í™•íˆ êµ¬ì¡°í™”í•˜ì—¬ ì„¤ëª…í•©ë‹ˆë‹¤.
-   **ì •ë³´ì˜ ì¡°í•©**: í•„ìš”í•œ ê²½ìš°, ì—¬ëŸ¬ ë³µì§€ ì„œë¹„ìŠ¤ë¥¼ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìµœì í™”ëœ 'ì„œë¹„ìŠ¤ ì¡°í•©'ì„ ì œì•ˆí•©ë‹ˆë‹¤.

**[4ë‹¨ê³„: ìê²© ìš”ê±´ ëª…ì‹œ ë° ìµœì¢… ê²€ìˆ˜]**
-   **ì—„ê²©í•œ ì •ë³´ ì„ ë³„**: 'ìƒíƒœ ì •ë³´'ì™€ 'ì§€ì› í•„ìš” ì‚¬í•­'ì— ë¶€í•©í•˜ì§€ ì•ŠëŠ” ì •ë³´ëŠ” ë‹µë³€ì—ì„œ ê³¼ê°íˆ ì œì™¸í•©ë‹ˆë‹¤.
-   **ìê²© ìš”ê±´ ëª…ì‹œ ë° ì•ˆë‚´**: ë§Œì•½ ì£¼ì–´ì§„ ì •ë³´ë§Œìœ¼ë¡œ ì‚¬ìš©ìê°€ ì§€ì› ëŒ€ìƒì¸ì§€ ëª…í™•íˆ íŒë‹¨í•  ìˆ˜ ì—†ë‹¤ë©´, **"ì´ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì‹œë ¤ë©´ [ì„œë¹„ìŠ¤ ì œê³µ ëŒ€ìƒ]ì— í•´ë‹¹í•˜ì…”ì•¼ í•©ë‹ˆë‹¤."** ì™€ ê°™ì´ ê²€ìƒ‰ëœ ì„œë¹„ìŠ¤ì˜ ê³µì‹ì ì¸ ì§€ì› ëŒ€ìƒì„ ëª…í™•íˆ ì•Œë ¤ì£¼ê³ , ë³¸ì¸ì´ ì—¬ê¸°ì— í•´ë‹¹í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•œë‹¤ê³  ì•ˆë‚´í•©ë‹ˆë‹¤.
-   **ë§ˆë¬´ë¦¬**: "ì•ˆë‚´í•´ ë“œë¦° ë‚´ìš©ì´ ë³´íƒ¬ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤. ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë‹¤ì‹œ ì°¾ì•„ì£¼ì‹­ì‹œì˜¤." ì™€ ê°™ì´ ì „ë¬¸ê°€ë¡œì„œ ê²©ë ¤í•˜ë©° ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.
-   **ì •ë³´ ë¶€ì¡± ì‹œ**: ë§Œì•½ ì ì ˆí•œ ì •ë³´ê°€ ì „í˜€ ì—†ë‹¤ë©´, "ì•ˆíƒ€ê¹ê²Œë„ ë¬¸ì˜í•˜ì‹  ë‚´ìš©ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì„œë¹„ìŠ¤ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¤ë¥¸ ë°©ë²•ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ, ê±°ì£¼ì§€ ì£¼ë¯¼ì„¼í„°ë‚˜ ë³´ê±´ë³µì§€ìƒë‹´ì„¼í„°(êµ­ë²ˆì—†ì´ 129)ì— ë¬¸ì˜í•´ë³´ì‹œëŠ” ê²ƒì„ ê¶Œí•´ë“œë¦½ë‹ˆë‹¤."ë¼ê³  ëŒ€ì•ˆì„ ì œì‹œí•˜ë©° ì†”ì§í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.

---
[ê´€ë ¨ ì„œë¹„ìŠ¤ ì •ë³´]
{context}
---
[ì‚¬ìš©ì ì§ˆë¬¸]
{question}
---
[30ë…„ ê²½ë ¥ ë³µì§€ ì „ë¬¸ê°€ ì§€ë‹ˆì˜ ìµœì¢… ë‹µë³€]
"""
        final_chain = self._create_chain(final_template, StrOutputParser())
        final_response = final_chain.invoke({
            "question": user_message, "context": context_string, "chat_history": chat_history
        })
        
        return f'{final_response}', "NORMAL"
    
    